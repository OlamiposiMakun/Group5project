import random

# H = happiness values
H = [10, 8, 6, 4]
# D = deviation value
D = [4, 6, 8, 10]


# Exploit code

# Get random number for a normal distribution with
# mean of h and standard deviation of d.
def generate_happiness(H1, D1):
    return random.normalvariate(H1, D1)


def exploitOnly():
    c1 = (H[0], D[0])
    c2 = (H[1], D[1])
    c3 = (H[2], D[2])
    c4 = (H[3], D[3])
    # make list to store the happiness values for each cafeteria
    happiness_values = []
    # Visit each cafeteria once and generate happiness values
    happiness_values.append(generate_happiness(*c1))
    happiness_values.append(generate_happiness(*c2))
    happiness_values.append(generate_happiness(*c3))
    happiness_values.append(generate_happiness(*c4))
    # Find the index of the best cafeteria
    best_cafeteria = happiness_values.index(max(happiness_values))
    # Visit the best cafeteria for the next 196 days and generate happiness values
    for i in range(196):
        happiness_values.append(generate_happiness(*[c1, c2, c3, c4][best_cafeteria]))
    # Return the sum of all the happiness values
    return sum(happiness_values)


# eGreedy task

def eGreedy(e=10) -> float:
    # Store and update happiness values and time of visits for each cafeteria
    # Index: 0 = c1, 1 = c2, 2 = c3, 3 = c4
    happiness_values = [0, 0, 0, 0]
    visit_count = [1, 1, 1, 1]

    # Day 1-4 simulate the values
    # set the simulated value to the happiness values
    happiness_values[0] = random.normalvariate(H[0], D[0])
    happiness_values[1] = random.normalvariate(H[1], D[1])
    happiness_values[2] = random.normalvariate(H[2], D[2])
    happiness_values[3] = random.normalvariate(H[3], D[3])

    # Then create a loop determine for the next 196 days
    # determine if we're going to the random or the best
    for i in range(196):
        visit_random_cafe = random.random()

        # I will visit a random cafe
        if visit_random_cafe < (e / 100):
            # Choose a random cafeteria
            random_cafe = random.randint(0, 3)
            visit_count[random_cafe] += 1
            # generate a random value for happiness based on its normal distribution
            happiness = random.normalvariate(H[random_cafe], D[random_cafe])
            # update the values
            happiness_values[random_cafe] += happiness

        # I will visit the cafeteria with the highest average happiness value
        else:
            # a list of averages
            averages = [happiness_values[0] / visit_count[0],
                        happiness_values[1] / visit_count[1],
                        happiness_values[2] / visit_count[2],
                        happiness_values[3] / visit_count[3]]
            # Find the best cafe
            # Best cafe will not always be the same
            best_cafe = averages.index(max(averages))

            happiness = random.normalvariate(H[best_cafe], D[best_cafe])
            # update the values
            visit_count[best_cafe] += 1
            happiness_values[best_cafe] += happiness
    total_happiness_value = sum(happiness_values)
    return total_happiness_value


# exploreOnly task




def exploreOnly():
    total_happiness = []
    # list to store happiness values in
    for cafeteria in range(4):  # generate happiness value for each cafeteria
        for day in range(50):  # generate happiness values for 50 days for each cafeteria
            # generate a new happiness value
            happiness = random.normalvariate(H[cafeteria], D[cafeteria])
            total_happiness.append(happiness)
    # return sum of all happiness values
    return sum(total_happiness)




# Simulation Task:
def simulation(t, e=10):
    optimalhappiness = max(H) * 200

    exploreonlyExphappiness = 50 * H[0] + 50 * H[1] + 50 * H[2] + 50 * H[3]
    exploreonlyExregret = optimalhappiness - exploreonlyExphappiness

    exploitonlyExhappiness = H[0] + H[1] + H[2] + H[3] + 196 * max(H)
    exploitonlyExregret = optimalhappiness - exploitonlyExhappiness

    egreedyexpdays = ((e / 100) * 200) / len(H)  # defines the amount of days per cafeteria for exploration
    daysofeGreedyExploitation = ((100 - e) / 100) * 200  # defines the amount of exploitation days(days going to the best resturant)
    eGreedyExhappiness = max(H) * daysofeGreedyExploitation + H[0] * egreedyexpdays + H[1] * egreedyexpdays + H[2] * egreedyexpdays + H[3] * egreedyexpdays

    eGreedyregret = optimalhappiness - eGreedyExhappiness

    eGreedysum = 0
    exploreOnlysum = 0
    exploitOnlysum = 0

    for i in range(t):  # acuumilation loop that adds all the function specific generated values to a variable based on the "t"
        eGreedysum = eGreedysum + eGreedy(e)
        exploreOnlysum = exploreOnlysum + exploreOnly()
        exploitOnlysum = exploitOnlysum + exploitOnly()

    simulatedegreedyhappiness = eGreedysum / t  # divides the total amount of generated values by the amount of times the loop ran.(Providing an average)
    simulatedegreedyregret = optimalhappiness - simulatedegreedyhappiness

    simulatedexplorehappiness = exploreOnlysum / t
    simulatedexploreregret = optimalhappiness - simulatedexplorehappiness

    simulatedexploithappiness = exploitOnlysum / t
    simulatedexploitregret = optimalhappiness - simulatedexploithappiness
    # Prints all the return values in a very pretty matter
    print("Optimum Happiness: " + "{:.2f}".format(optimalhappiness))
    print(" ")
    print("Explore Only: ")
    print("Expected Happiness: " + "{:.2f}".format(exploreonlyExphappiness))
    print("Expected Regret: " + "{:.2f}".format(exploreonlyExregret))
    print("Simulated Happiness: " + "{:.2f}".format(simulatedexplorehappiness))
    print("Simulated Regret: " + "{:.2f}".format(simulatedexploreregret))
    print(" ")
    print("Exploit Only: ")
    print("Expected Happiness: " + "{:.2f}".format(exploitonlyExhappiness))
    print("Expected Regret: " + "{:.2f}".format(exploitonlyExregret))
    print("Simulated Happiness: " + "{:.2f}".format(simulatedexploithappiness))
    print("Simulated Regret: " + "{:.2f}".format(simulatedexploitregret))
    print(" ")
    print("eGreedy: ")
    print("Expected Happiness: " + "{:.2f}".format(eGreedyExhappiness))
    print("Expected Regret: " + "{:.2f}".format(eGreedyregret))
    print("Simulated Happiness: " + "{:.2f}".format(simulatedegreedyhappiness))
    print("Simulated Regret: " + "{:.2f}".format(simulatedegreedyregret))


