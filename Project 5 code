import random
# H = happiness values
H = [7, 4, 10, 5]
# D = deviation value
D = [3, 10, 6, 2]



# Exploit code

# Get random number for a normal distribution with
# mean of h and standard deviation of d.
def generate_happiness(h1, d1) -> float:
    return random.normalvariate(h1, d1)


print(generate_happiness(7, 3))


def exploitonly():
    c1 = (H[0], D[0])
    c2 = (H[1], D[1])
    c3 = (H[2], D[2])
    c4 = (H[3], D[3])
    # make list to store the happiness values for each cafeteria
    happiness_values = []
    # Visit each cafeteria once and generate happiness values
    happiness_values.append(generate_happiness(*c1))
    happiness_values.append(generate_happiness(*c2))
    happiness_values.append(generate_happiness(*c3))
    happiness_values.append(generate_happiness(*c4))
    # Find the index of the best cafeteria
    best_cafeteria = happiness_values.index(max(happiness_values))
    # Visit the best cafeteria for the next 196 days and generate happiness values
    for i in range(196):
        happiness_values.append(generate_happiness(*[c1, c2, c3, c4][best_cafeteria]))
    # Return the sum of all the happiness values
    return sum(happiness_values)


print(exploitonly())


# eGreedy task

def eGreedy(e=10) -> float:
    # Store and update happiness values and time of visits for each cafeteria
    # Index: 0 = c1, 1 = c2, 2 = c3, 3 = c4
    happiness_values = [0, 0, 0, 0]
    visit_count = [1, 1, 1, 1]

    # Day 1-4 simulate the values
    # set the simulated value to the happiness values
    happiness_values[0] = random.normalvariate(H[0], D[0])
    happiness_values[1] = random.normalvariate(H[1], D[1])
    happiness_values[2] = random.normalvariate(H[2], D[2])
    happiness_values[3] = random.normalvariate(H[3], D[3])


    # Then create a loop determine for the next 196 days
    # determine if we're going to the random or the best
    for i in range(196):
        visit_random_cafe = random.random()

        # I will visit a random cafe
        if visit_random_cafe < (e/100):
            # Choose a random cafeteria
            random_cafe = random.randint(0, 3)
            visit_count[random_cafe] += 1
            # generate a random value for happiness based on its normal distribution
            happiness = random.normalvariate(H[random_cafe], D[random_cafe])
            # update the values
            happiness_values[random_cafe] += happiness
        
        # I will visit the cafeteria with the highest average happiness value
        else:
            # a list of averages
            averages = [happiness_values[0] / visit_count[0],
                        happiness_values[1] / visit_count[1],
                        happiness_values[2] / visit_count[2],
                        happiness_values[3] / visit_count[3]]
            # Find the best cafe
            # Best cafe will not always be the same
            best_cafe = averages.index(max(averages))

            happiness = random.normalvariate(H[best_cafe], D[best_cafe])
            # update the values
            visit_count[best_cafe] += 1
            happiness_values[best_cafe] += happiness
    total_happiness_value = sum(happiness_values)
    return total_happiness_value



# exploreOnly task

def generate_happiness(H1, D1):
    return random.normalvariate(H1, D1)

def exploreOnly():
    total_happiness = []
    # list to store happiness values in
    for cafeteria in range(4):  # generate happiness value for each cafeteria
        for day in range(50):  # generate happiness values for 50 days for each cafeteria
        # generate a new happiness value
            happiness = random.normalvariate(avg_happiness[cafeteria], standard_dev[cafeteria])
            total_happiness.append(happiness)
    # return sum of all happiness values
    return sum(total_happiness)

total = 0
for i in range(1000):
    total += exploreOnly()
print(total/1000)

#Simulation Task:
def simulation(t, e=10):



 optimalhappiness = max(h)*200

 exploreonlyExphappiness = 50*h[0] + 50*h[1] + 50*h[2] + 50*h[3]
 exploreonlyExregret = optimalhappiness - exploreonlyExphappiness

 exploitonlyExhappiness = h[0] + h[1] + h[2] + h[3] + 196*max(h)
 exploitonlyExregret = optimalhappiness - exploitonlyExhappiness

 egreedyexpdays = ((e/100)*200)/len(h) #defines the amount of days per cafeteria for exploration
 daysofeGreedyExploitation = ((100-e)/100)*200 #defines the amount of exploitation days(days going to the best resturant)
 eGreedyExhappiness = max(h)*daysofeGreedyExploitation + h[0]*egreedyexpdays + h[1]*egreedyexpdays + h[2]*egreedyexpdays + h[3]*egreedyexpdays

 eGreedyregret = optimalhappiness - eGreedyExhappiness

 eGreedysum = 0
 exploreOnlysum = 0
 exploitOnlysum = 0

 for i in range(t): #acuumilation loop that adds all the function specific generated values to a variable based on the "t"
  eGreedysum = eGreedysum + eGreedy(e)
  exploreOnlysum = exploreOnlysum + exploreOnly()
  exploitOnlysum = exploitOnlysum + exploitOnly()

 simulatedegreedyhappiness  = eGreedysum/t #divides the total amount of generated values by the amount of times the loop ran.(Providing an average)
 simulatedegreedyregret = optimalhappiness - simulatedegreedyhappiness

 simulatedexplorehappiness = exploreOnlysum/t
 simulatedexploreregret = optimalhappiness - simulatedexplorehappiness

 simulatedexploithappiness = exploitOnlysum/t
 simulatedexploitregret = optimalhappiness - simulatedexploithappiness
 #Prints all the return values in a very pretty matter
 print("Optimum Happiness: " + "{:.2f}".format(optimalhappiness))
 print(" ")
 print("Explore Only: ")
 print("Expected Happiness: " + "{:.2f}".format(exploreonlyExphappiness))
 print("Expected Regret: " + "{:.2f}".format(exploreonlyExregret))
 print("Simulated Happiness: " + "{:.2f}".format(simulatedexplorehappiness))
 print("Simulated Regret: " + "{:.2f}".format(simulatedexploreregret))
 print(" ")
